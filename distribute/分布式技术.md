

### 一致性哈希

一致性哈希（DHT）是一种主要应用于分布式存储的技术，常用在负载均衡的架构设计中，可以有效地解决分布式存储结构下动态增加节点和删除节点所带来的数据迁移问题。

为了解决缓存节点分布不均匀的情况，使用虚拟节点，将节点的ip地址加上后缀，映射到环形空间中。




### 分布式锁
#### 分布式锁的要求
1. 要互斥，在同一个时间只能有一个机器的一个线程访问资源
2. 获取锁和释放锁的速度要快
3. 可重入
4. 要有阻塞，能够唤醒阻塞的线程，而不是重复性尝试获取锁
5. 设置过期时间

实现可以使用：DB锁、Memcached、Redis、Zookeeper、Chubby

#### DB锁
数据库中的表结构可以如下所示：
```
CREATE TABLE `lock_table` (
  `id` int(11) unsigned NOT NULL COMMENT '主键',
  `key_id` bigint(20) NOT NULL COMMENT '分布式key',
  `memo` varchar(43) NOT NULL DEFAULT '' COMMENT '可记录操作内容',
  `update_time` datetime NOT NULL COMMENT '更新时间',
  PRIMARY KEY (`id`,`key_id`),
  UNIQUE KEY `key_id` (`key_id`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
```
- 获得锁向表中插入一条记录，释放锁则删除这条记录，唯一索引保证了记录只能被插入一次，用记录是否存在来判断是否处于锁定状态
- 由于获取锁等于在数据库表中添加或者修改值，释放锁等于在数据库表中删除或者修改值，因此性能不高
- 对于client宕机导致锁未释放，需要额外设置清理程序，来定时清理过期未释放的锁
- 通过数据库的同步复制，vip切换master来解决分布式环境下的单点问题

#### Redis的实现
- 使用SETNX(set if not exist)指令插入一个键值对，如果Key存在，则返回false，否则插入返回true，加锁操作：

  ```
  方法1. 使用SET
  set key value NX PX expireTime;
  方法2.使用SETEX
  SETEX key seconds value
  ```

  

- 可以设置过期时间

- 对于高可用性，通过集群和Master-Slave来解决。或者使用多个Redis实例来实现分布式锁，当大多数Redis实例有响应的时候才认为获得锁成功

- 如果client没能释放锁，但是由于超时而被Redis释放了锁，其他client获取了锁资源，而原来的client仍然对数据进行写入，为了解决这个问题，可以编写续锁程序，也就是在获取锁之后，释放锁之前，定时进行锁续约

- 判断操作和设置过期时间等操作是独立的操作，非原子性，解决方法是使用单条的语句；

- 加锁需要添加线程唯一标识(从而自己加的锁只能自己解开)，设置过期时间，没有已存在的锁时才加锁

- 解锁的时候要判断当前的线程是否是原先的线程，只能解自己的锁，不然容易解掉其他线程的锁，考虑原子性，使用Lua脚本，代码如下：

  ```java
  if redis.call("get",KEYS[1]) == ARGV[1]
  then
      return redis.call("del",KEYS[1])
  else
      return 0
  end
     
  ```

**Redis分布式锁的缺陷**：

1. 客户端长时间阻塞导致锁失效：client1持有了锁，然而由于网络问题或者GC问题，导致Redis中的所信息失效了，此时client2获取锁成功并且修改了数据。而client1以为自己还持有锁，直接修改数据，导致数据的不一致。
2. Redis服务器时间飘逸：Redis服务器相比较客户端快了3分钟，因此当client获取了锁，在9点03分过期，而Redis服务器中的锁信息在9点就失效了，导致其他客户端也能够获取到锁。
3. 主从切换导致锁信息丢失：对于一主一从的Redis服务，client1持有锁，保存在Master节点中，由于主从异步复制，当Master节点挂掉的时候，Slave节点可能还没有获取到锁的信息。从而Slave节点升为Master节点后，如果有client2获取锁，是能够获取到的，在这个瞬间，client1和client2都持有了锁。

java版本的Redis分布式框架：Redission

#### Zookeeper的实现

- zab协议保证了数据的一致性
- watcher机制，实现了通知机制
- zookeeper集群保证了高可用性

1. 创建一个锁目录：/lock;
2. 当客户端需要获取锁的时候，在/lock目录下创建临时的有序的子节点;
3. 客户端获取/lock下的子节点列表，判断自己的子节点是否为序号最小的子节点，如果是则获取锁成功；否则监听前一个子节点，获得子节点的变更通知后重复此过程；
4. 执行业务代码，执行完成后，删除子节点


#### 总结
##### 性能
DB锁 < Zookeeper < Redis
##### 锁唤醒
DB锁和Redis没有，Zookeeper通过watcher来实现了锁唤醒机制
##### 可用性
- DB锁通过数据库同步复制，vip切换Master
- Redis通过集群或者Master-Slave
- Zookeeper本身是通过zab协议集群部署来实现的

##### 避免死锁
- DB锁在应用层编写清理程序，来定时清理超时的锁
- Reids通过设置过期时间
- Zookeeper通过临时节点

### 分布式事务
指事务的操作位于不同的节点上，需要保证事务的ACID特性

分布式锁和分布式事务区别：
- 锁问题的关键在于进程操作的互斥性，例如多个进程同时修改账户的余额，如果没有互斥关系就会导致账户的余额不正确；
- 事务问题的关键在于事务涉及的操作需要满足ACID特性，例如要满足原子性操作需要操作要么执行，要么不执行

实现分布式事务可以使用2PC、本地消息表

#### 2PC
两阶段提交(Two-phase commit)，通过引入协调者来协调参与者的行为，并最终决定这些参与者是否要真正执行事务

运行过程：
1. 协调者询问参与者事务是否执行成功，参与者发回事务执行结果
2. 如果事务在各个参与者中都执行成功，协调者发送消息让参与者全部提交事务，否则让参与者全部回滚事务

#### 本地消息表
本地消息表和业务表在同一个数据库中，对这两个表可以使用本地事务操作，满足ACID特性，之后使用消息队列来保证最终一致性

1. 分布式事务操作一方A完成写业务数据操作后向本地消息表发送消息，本地事务能够保证消息一定会被写入本地消息表中；
2. 将本地消息表中的消息发送给消息队列，如果转发成功则删除表中的消息，否则重试；
3. 分布式事务操作的另一方B从消息队列中读取消息，并且在本地执行消息中的操作

### CAP
- Consistency（一致性）：系统中所有节点的数据状态（版本）是相同的
- Availability（可用性）：系统会处理和响应每个请求
- Partition Tolerance（分区容忍性）：如果一些节点宕机或者网络故障，系统还能够提供服务

一个分布式系统不可能同时满足以上3个，只能同时满足2个，而分布式系统中，总是假设网络是不可靠的，所以分区容忍性必不可少
- 为了保证可用性（AP），允许读取所有节点的数据，但是数据会不一致
- 为了保证一致性（CP），不能访问未同步完成的节点，失去了部分的可用性

### BASE
BASE理论是对CAP可用性和一致性权衡的结果，主要思想是：即使系统无法做到强一致性，但是需要根据自身业务特点，采用适当的方式使系统达到最终一致性

- Basically Available(基本可用)：分布式系统在出现故障的时候，保证核心可用，允许损失部分可用性。比如在电商做促销的时候，访问量大的时候部分用户会被引导到一个降级的页面
- Soft-state(软状态/柔性事务)：允许系统的数据存在中间状态
- Eventual Consistence(最终一致性)

### Paxos
用于达成共识性问题，对多个节点的值，能够产生唯一一个输出

包括了三种节点：
- Proposer：提议一个值
- Acceptor：对每个提议进行投票
- Learner：获得提议的最终结果，不存与投票


### Raft
Raft是分布式一致性协议，主要用来竞选主节点

有三种节点：Follower、Candidate、Leader。Leader会周期性发送心跳包给Follower。每个Follower设置了一个随机的竞选超时时间，如果时间过了没有收到Leader的心跳包，那么就会变成Candidate，进入竞选阶段
1. A节点没有收到Leader的心跳包，进入竞选阶段
2. A节点发送投票请求给其他所有节点
3. 其他节点会对请求进行回复，如果超过一半节点回复了，那么A节点就从Candidate变为Leader
4. A节点成为Leader后周期性发送心跳包给其他所有节点，Follower接收到心跳包后，会重新开始计时

### 分布式架构面临的环境问题
- 网络是不可靠的
- 请求是有延迟的
- 有限的带宽
- 网络不安全
- 系统拓补结构会改变
- 网络不是同质的
- 数据传输是有代价的
- 没有管理员在管理这个系统

### 开源项目
针对分布式事务，业内比较不错的开源项目：

- ByteTCC   : ByteTCC 是基于 Try-Confirm-Cancel（TCC）机制的分布式事务管理器的实现。相关阅读：关于如何实现一个 TCC 分布式事务框架的一点思考
- Seata :Seata 是一款开源的分布式事务解决方案，致力于在微服务架构下提供高性能和简单易用的分布式事务服务。
- Hmily  : 金融级分布式事务解决方案